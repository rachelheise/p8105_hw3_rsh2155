---
title: "P8105 Homework 3"
author: "Rachel Heise"
date: "10/9/2020"
output: github_document
---

## Problem 1

```{r setup, include=FALSE}
library(p8105.datasets)
library(tidyverse)
library(dplyr)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = 0.6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "right"))

options(
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_color_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```

```{r, results = "hide"}
data("instacart")
head(instacart)
```


This data has `r nrow(instacart)` observations and `r ncol(instacart)` columns. The data contains both user/order variables and item variables. Variables relating to the user and order are the user ID, order ID, order day, order hour, and days since prior order. Item variables include product ID, reordered (whether or not the user had ordered this previously), product name, aisle, and department. There are multiple aisles contained within departments.

Analyze number of aisles and which has the most items ordered from.
```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

There are 134 aisles, and the most ordered items are from fresh vegetables, fresh fruits, and packaged vegetables fruits.

Plot items ordered in each aisle, but only those with greater than 10,000 items ordered.
```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  labs(
    title = "Items Ordered per Aisle",
    x = "Aisle",
    y = "Number of Items"
    )
```


Make a table of the most popular items in three aisles.
```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

Table of mean time of day that Pink Lady Apples and Coffee Ice Cream are ordered.
```{r, message = FALSE}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable()

```


## Problem 2

Import and clean accelerometer data.
```{r, results = "hide", message = FALSE}
accel_df = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_minute",
    values_to = "activity_count"
    ) %>% 
  mutate(activity_minute = substr(activity_minute, 10, 13)) %>% 
  mutate(activity_minute = as.numeric(activity_minute)) %>% 
  mutate(weekday_weekend = recode(day, "Monday" = "weekday", "Tuesday" = "weekday", "Wednesday" = "weekday", "Thursday" = "weekday", "Friday" = "weekday", "Saturday" = "weekend", "Sunday" = "weekend"))
```

There are `r ncol(accel_df)` variables in this data set, and `r nrow(accel_df)` observations. Data of interest includes the activity period and activity count, which are respectively the minute of the day the measurement was taken and the amount of activity that the man did during that minute. The week and day of the five week sample are included, as well as what day of the week each measurement was taken during. This is additionally broken into weekday and weekend categories.


```{r, message = FALSE}
accel_df %>% 
  group_by(day, week) %>% 
  summarize(daily_activity = sum(activity_count)) %>%
  pivot_wider(
    names_from = day,
    values_from = daily_activity) %>% 
  relocate(week, Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday) %>% 
  knitr::kable()
```

From the above table, it appears there were two days where this man did not wear the accelerometer because the activity count is at the baseline (day 24 and day 31). It does not appear that his activity levels are trending over time, but there are a few days in these five weeks where he had quite high activity levels, greater than 600,000 per day, and a low day, under 100,000 per day.

Create a single-panel plot showing 24 hour activity levels.
```{r, messsage = FALSE, warning = FALSE}
accel_df %>%
  group_by(day, activity_minute) %>% 
  summarize(mean_activities = mean(activity_count)) %>% 
  ggplot(aes(x = activity_minute, y = mean_activities, color = day)) + 
  scale_x_continuous(
    breaks = c(1, 360, 720, 1080, 1440),
    labels = c("12am", "6am", "12pm", "6pm", "12pm")
  ) +
  scale_y_continuous(limit = c(0, 750)
  ) +
  geom_smooth(se = FALSE) +
  viridis::scale_color_viridis(
    name = "Day",
    discrete = TRUE) +
  labs(
    title = "Daily Activity Plot",
    x = "Time of Day",
    y = "Activity Level"
  )

```

From the above plot, we can see that starting at around midnight every day, on average the individual was moving hardly at all which is to be expected because he is likely asleep. Some noteworthy spikes on the plot are on Sundays, where activity was quite high between 9 am and noon, and on Fridays, activity was high between 8 pm and 10 pm. On average, the lowest activity day of the week was Saturday; however, we saw above that there were two Saturdays he did not wear the accelerometer. In general, all days have steadily increasing activity from 6 am to 10 am, at which point activity stabilizes before reducing around 9 pm.



## Problem 3

```{r}
data("ny_noaa")

ny_df = ny_noaa %>% 
  mutate(
    tmin = as.numeric(tmin), tmax = as.numeric(tmax)) %>% 
  mutate(
    tmin = tmin / 10,
    tmax = tmax / 10)
```

This data set contains data, for each day and New York state weather station, on daily precipitation, max and min temperatures, and snow depth. There are `r nrow(ny_df)` observations and `r ncol(ny_df)` variables. Tmin and tmax are the minimum and maximum daily temperatures, respectively, in degrees C. ID provides the weather station ID for each station. Precipitation data is given in tenths of a mm, as well as daily snowfall (mm) and snow depth (mm). Missing data is a major concern with this data set; many of the rows of data only contain information on one of the precipitation and temperature variables.


Perform further data cleaning:
```{r}
ny_df = ny_df %>% 
  separate(date, into = c("year", "month", "day"), sep = "[-]", convert = TRUE) %>% 
  mutate(snow = as.double(snow),
         prcp = as.numeric(tmin)) %>% 
  mutate(prcp = prcp / 10)

ny_df %>% 
  count(snow) %>% 
  arrange(desc(n))
```

The most commonly observed amounts of snowfall are 0 and NA. 0 is quite likely because during the summer and warmer parts of the spring and fall in NY state, there will mostly be no snow. 

Create a two-panel plot of average max temperature for January and July.
```{r, warning = FALSE, message = FALSE}
month_names = c(`1` = "January", `7` = "July")


ny_df %>% 
  group_by(id, month, year) %>% 
  filter(month %in% c(1,7)) %>% 
  summarize(mean_tmax = mean(tmax, na.rm = TRUE)) %>%
  na.omit() %>% 
  ggplot(aes(x = year, y = mean_tmax, color = id)) +
  geom_line(alpha = 0.5) +
  geom_point() +
  facet_grid(. ~ month, labeller = as_labeller(month_names)) +
  theme(legend.position = "none", panel.spacing.x = unit(20, "pt")) +
  labs(
    title = "January and July Temperatures",
    x = "Year",
    y = "Mean Temperature Max (deg C)"
  ) +
  viridis::scale_color_viridis(
    discrete = TRUE) +
  scale_x_continuous(
    breaks = c(1980, 1990, 2000, 2010),
    labels = c("1980", "1990", "2000", "2010")
  )
  
  
```

The above plot shows the mean temperatures at each station for the months of January and July, from 1980 to 2010. As expected, July temperatures are much warmer than January temperatures for all stations in New York. The January temperatures seem to have warmed over time, and there is also greater spread of temperatures in the 2000s than in the 1980s and 1990s. July temperatures look more stable over time. There are outliers on both plots, and one point in January of 1982 particularly stands out, as well as a point in July of 1988. Although there is variation between stations in each year, across years they tend to follow similar patterns: when one station has a warm month, most other stations also have a warm month.

Create two-panel plot of min vs. max temperatures and snowfall distributions.
```{r, warning = FALSE}

tmax_tmin = ny_df %>% 
  ggplot(aes(x = tmax, y = tmin)) +
  geom_hex() +
  labs(
    title = "Max and Min Temperatures",
    x = "Max Temperature (deg C)",
    y = "Min Temperature (deg C)"
  ) +
  viridis::scale_color_viridis(
    discrete = TRUE)


snowfall = ny_df %>% 
  filter(snow > 0, snow < 100) %>% 
  mutate(year = factor(year)) %>% 
  ggplot(aes(x = year, y = snow)) +
  geom_boxplot(alpha = 0.5) +
  labs(
    title = "Snowfall Distribution",
    x = "Year",
    y = "Snowfall"
  ) +
  viridis::scale_color_viridis(
    discrete = TRUE) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

tmax_tmin / snowfall
```


